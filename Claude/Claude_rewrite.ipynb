{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import numpy.typing as npt\n",
    "from typing import List, Tuple, Any\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_laplacian_3D(M):\n",
    "    #Make a big matrix to incorporate boundary conditions\n",
    "    #for this implementation, we will have periodic conditions in x and y and no flux in Z.\n",
    "    #This involves literally just adding rows such that the boundary conditions are satisfied.\n",
    "    #For periodic, the padded layer will be the value from the opposite side of the matrix,\n",
    "    #for no flux, the padded layer (-1) equals the (1) layer such that the central difference around (0) is 0\n",
    "    shp = np.shape(M)\n",
    "    \n",
    "    #make the padded matrix\n",
    "    M_padded = np.zeros((shp[0]+2,shp[1]+2,shp[2]+2))\n",
    "    \n",
    "    #put the original matrix inside\n",
    "    M_padded[1:-1,1:-1,1:-1] = M.copy()\n",
    "    \n",
    "    #pad the edges, starting with Z\n",
    "    M_padded[:,:,0] = M_padded[:,:,2]\n",
    "    M_padded[:,:,-1] = M_padded[:,:,-3]\n",
    "    \n",
    "    #pad the edges, X direction\n",
    "    M_padded[0,:,:] = M_padded[-2,:,:]\n",
    "    M_padded[-1,:,:] = M_padded[1,:,:]\n",
    "    \n",
    "    #pad the edges, Y direction\n",
    "    M_padded[:,0,:] = M_padded[:,-2,:]\n",
    "    M_padded[:,-1,:] = M_padded[:,1,:]\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #using the 27 point stencil\n",
    "    #k = 1/26*[[[2,3,2],[3,6,3],[2,3,2]],[[3,6,3],[6,-88,6],[3,6,3]],[[2,3,2],[3,6,3],[2,3,2]]]\n",
    "    \n",
    "    #7 point stencil\n",
    "    k = [[[0,0,0],[0,1,0],[0,0,0]],[[0,1,0],[1,-6,1],[0,1,0]],[[0,0,0],[0,1,0],[0,0,0]]]\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    L = convolve(M_padded, k)\n",
    "    M_upd = L[2:-2,2:-2,2:-2]\n",
    "    \n",
    "    #L = convolve(M_padded, k, mode='same')\n",
    "    #M_upd = L[1:-1,1:-1,1:-1]\n",
    "    \n",
    "    return M_upd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nutrient_fields(S_list, D_list, cells, diff, dt, uptake_rates, release_rates):\n",
    "    \"\"\"Update nutrient concentration fields for one diffusion timestep\"\"\"\n",
    "    n_nutrients = len(S_list)\n",
    "    shape_S = S_list[0].shape\n",
    "    S_new_list = []\n",
    "    \n",
    "    uptake_matrix, release_matrix = process_cell_nutrient_interactions(\n",
    "        cells, S_list, shape_S, diff, dt, uptake_rates, release_rates\n",
    "    )\n",
    "    \n",
    "    for i in range(n_nutrients):\n",
    "        laplacian = compute_laplacian_3d(S_list[i])\n",
    "        diffusion_term = D_list[i] * laplacian\n",
    "        source_sink_term = release_matrix[i] - uptake_matrix[i]\n",
    "        S_new = S_list[i] + dt * (diffusion_term + source_sink_term)\n",
    "        S_new = np.maximum(S_new, 0)\n",
    "        S_new_list.append(S_new)\n",
    "    \n",
    "    return S_new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cell_population(cells, dt_cell):\n",
    "    \"\"\"\n",
    "    Update cell population through death and reproduction\n",
    "    \n",
    "    Parameters:\n",
    "    cells: list of Cell objects\n",
    "    dt_cell: timestep for cell updates\n",
    "    \n",
    "    Returns:\n",
    "    List of new cells created during reproduction\n",
    "    List of indices of cells that died\n",
    "    \"\"\"\n",
    "    new_cells = []\n",
    "    dead_cell_indices = []\n",
    "    \n",
    "    for idx, cell in enumerate(cells):\n",
    "        if not cell.is_alive:\n",
    "            continue\n",
    "            \n",
    "        # Process death\n",
    "        if np.random.random() < cell.death_rate * dt_cell:\n",
    "            cell.is_alive = False\n",
    "            dead_cell_indices.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # Check reproduction conditions\n",
    "        can_reproduce = True\n",
    "        for nutrient_idx in range(cell.dependencies.shape[0]):\n",
    "            if cell.dependencies[nutrient_idx, 0]:  # if cell needs this nutrient\n",
    "                if cell.internal_nutrients[nutrient_idx] < cell.alpha[nutrient_idx]:\n",
    "                    can_reproduce = False\n",
    "                    break\n",
    "        \n",
    "        # Process reproduction\n",
    "        if can_reproduce:\n",
    "            # Create new cell with small random displacement\n",
    "            new_cell = cell.reproduce()  # This should create a new cell object\n",
    "            if new_cell is not None:\n",
    "                new_cells.append(new_cell)\n",
    "    \n",
    "    return new_cells, dead_cell_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def michaelis_menten_uptake(S: float, vm: float, km: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate uptake rate using Michaelis-Menten kinetics\n",
    "    \n",
    "    Parameters:\n",
    "    S: local nutrient concentration\n",
    "    vm: maximum uptake rate\n",
    "    km: half-saturation constant\n",
    "    \n",
    "    Returns:\n",
    "    Uptake rate\n",
    "    \"\"\"\n",
    "    return vm * S / (S + km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cell_nutrient_interactions(cells, S_list, shape_S, diff, dt, vm_list, km_list, release_rates):\n",
    "    \"\"\"\n",
    "    Process nutrient uptake/release for all cells using Michaelis-Menten kinetics\n",
    "    \n",
    "    Parameters:\n",
    "    cells: list of Cell objects\n",
    "    S_list: list of nutrient concentration arrays\n",
    "    shape_S: shape of nutrient grids\n",
    "    diff: grid refinement factor\n",
    "    dt: timestep\n",
    "    vm_list: list of maximum uptake rates for each nutrient\n",
    "    km_list: list of half-saturation constants for each nutrient\n",
    "    release_rates: list of release rates for each nutrient\n",
    "    \"\"\"\n",
    "    n_nutrients = len(S_list)\n",
    "    uptake_matrix = np.zeros((n_nutrients, *shape_S))\n",
    "    release_matrix = np.zeros((n_nutrients, *shape_S))\n",
    "    \n",
    "    for cell in cells:\n",
    "        if not cell.is_alive:\n",
    "            continue\n",
    "            \n",
    "        i, j, k = int(cell.x // diff), int(cell.y // diff), int(cell.z // diff)\n",
    "        \n",
    "        if not (0 <= i < shape_S[0] and 0 <= j < shape_S[1] and 0 <= k < shape_S[2]):\n",
    "            continue\n",
    "            \n",
    "        for nutrient_idx in range(n_nutrients):\n",
    "            local_concentration = S_list[nutrient_idx][i, j, k]\n",
    "            \n",
    "            if cell.dependencies[nutrient_idx, 0]:  # uptake\n",
    "                # Calculate uptake using Michaelis-Menten kinetics\n",
    "                uptake_rate = michaelis_menten_uptake(\n",
    "                    local_concentration,\n",
    "                    vm_list[nutrient_idx],\n",
    "                    km_list[nutrient_idx]\n",
    "                )\n",
    "                \n",
    "                # Calculate actual uptake for this timestep\n",
    "                desired_uptake = uptake_rate * dt\n",
    "                actual_uptake = min(desired_uptake, local_concentration)\n",
    "                \n",
    "                uptake_matrix[nutrient_idx, i, j, k] += actual_uptake\n",
    "                cell.process_nutrient_uptake(nutrient_idx, actual_uptake)\n",
    "            \n",
    "            if cell.dependencies[nutrient_idx, 1]:  # release\n",
    "                release_amount = release_rates[nutrient_idx] * dt\n",
    "                release_matrix[nutrient_idx, i, j, k] += release_amount\n",
    "                cell.process_nutrient_release(nutrient_idx, release_amount)\n",
    "    \n",
    "    return uptake_matrix, release_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GridChunk:\n",
    "    \"\"\"Data class for holding chunk information for parallel processing\"\"\"\n",
    "    start_idx: Tuple[int, int, int]\n",
    "    end_idx: Tuple[int, int, int]\n",
    "    S_chunk: List[npt.NDArray]\n",
    "    cells_in_chunk: List[Any]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_grid_into_chunks(S_list: List[npt.NDArray], cells: List[Any], \n",
    "                          n_chunks: int) -> List[GridChunk]:\n",
    "    \"\"\"\n",
    "    Split the 3D grid and cells into chunks for parallel processing\n",
    "    \"\"\"\n",
    "    shape_S = S_list[0].shape\n",
    "    chunks_per_dim = int(np.cbrt(n_chunks))  # Cubic root for 3D splitting\n",
    "    \n",
    "    chunk_size = [s // chunks_per_dim for s in shape_S]\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(chunks_per_dim):\n",
    "        for j in range(chunks_per_dim):\n",
    "            for k in range(chunks_per_dim):\n",
    "                start_idx = (i * chunk_size[0], j * chunk_size[1], k * chunk_size[2])\n",
    "                end_idx = ((i + 1) * chunk_size[0], (j + 1) * chunk_size[1], \n",
    "                          (k + 1) * chunk_size[2])\n",
    "                \n",
    "                # Get cells in this chunk\n",
    "                cells_in_chunk = [\n",
    "                    cell for cell in cells if cell.is_alive and\n",
    "                    start_idx[0] <= cell.x < end_idx[0] and\n",
    "                    start_idx[1] <= cell.y < end_idx[1] and\n",
    "                    start_idx[2] <= cell.z < end_idx[2]\n",
    "                ]\n",
    "                \n",
    "                # Get nutrient chunks\n",
    "                S_chunk = [\n",
    "                    S[start_idx[0]:end_idx[0],\n",
    "                      start_idx[1]:end_idx[1],\n",
    "                      start_idx[2]:end_idx[2]].copy()\n",
    "                    for S in S_list\n",
    "                ]\n",
    "                \n",
    "                chunks.append(GridChunk(start_idx, end_idx, S_chunk, cells_in_chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk: GridChunk, D_list: List[float], diff: int, dt: float,\n",
    "                 uptake_rates: npt.NDArray, release_rates: npt.NDArray) -> Tuple[List[npt.NDArray], List[Any]]:\n",
    "    \"\"\"\n",
    "    Process a single chunk of the grid\n",
    "    \"\"\"\n",
    "    # Update nutrients in chunk\n",
    "    S_new_chunk = update_nutrient_fields(\n",
    "        chunk.S_chunk, D_list, chunk.cells_in_chunk, diff, dt,\n",
    "        uptake_rates, release_rates\n",
    "    )\n",
    "    \n",
    "    return S_new_chunk, chunk.cells_in_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_simulate_system(S_list: List[npt.NDArray], D_list: List[float], \n",
    "                           cells: List[Any], diff: int, dt_diff: float, \n",
    "                           dt_cell: float, uptake_rates: npt.NDArray, \n",
    "                           release_rates: npt.NDArray, total_time: float):\n",
    "    \"\"\"\n",
    "    Parallel implementation of system simulation\n",
    "    \"\"\"\n",
    "    steps_per_cell_update = int(dt_cell / dt_diff)\n",
    "    n_cell_updates = int(total_time / dt_cell)\n",
    "    \n",
    "    # Determine number of chunks based on CPU cores\n",
    "    n_cores = mp.cpu_count()\n",
    "    n_chunks = n_cores * 2  # Using 2 chunks per core for better load balancing\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_cores) as process_executor:\n",
    "        with ThreadPoolExecutor(max_workers=n_cores) as thread_executor:\n",
    "            \n",
    "            for cell_step in range(n_cell_updates):\n",
    "                # Parallel nutrient updates\n",
    "                for _ in range(steps_per_cell_update):\n",
    "                    # Split grid into chunks\n",
    "                    chunks = split_grid_into_chunks(S_list, cells, n_chunks)\n",
    "                    \n",
    "                    # Process chunks in parallel\n",
    "                    future_results = [\n",
    "                        process_executor.submit(\n",
    "                            process_chunk, chunk, D_list, diff, dt_diff,\n",
    "                            uptake_rates, release_rates\n",
    "                        )\n",
    "                        for chunk in chunks\n",
    "                    ]\n",
    "                    \n",
    "                    # Collect results\n",
    "                    chunk_results = [future.result() for future in future_results]\n",
    "                    \n",
    "                    # Merge chunk results back into main grid\n",
    "                    for chunk, (S_new_chunk, updated_cells) in zip(chunks, chunk_results):\n",
    "                        for i, S in enumerate(S_list):\n",
    "                            S[chunk.start_idx[0]:chunk.end_idx[0],\n",
    "                              chunk.start_idx[1]:chunk.end_idx[1],\n",
    "                              chunk.start_idx[2]:chunk.end_idx[2]] = S_new_chunk[i]\n",
    "                        \n",
    "                        # Update cell states\n",
    "                        for updated_cell in updated_cells:\n",
    "                            for cell in cells:\n",
    "                                if (cell.x == updated_cell.x and \n",
    "                                    cell.y == updated_cell.y and \n",
    "                                    cell.z == updated_cell.z):\n",
    "                                    cell.internal_nutrients = updated_cell.internal_nutrients\n",
    "                \n",
    "                # Parallel cell population updates\n",
    "                cell_chunks = np.array_split(cells, n_cores)\n",
    "                future_results = [\n",
    "                    thread_executor.submit(update_cell_population, chunk, dt_cell)\n",
    "                    for chunk in cell_chunks\n",
    "                ]\n",
    "                \n",
    "                # Collect and process cell updates\n",
    "                new_cells = []\n",
    "                dead_indices = []\n",
    "                offset = 0\n",
    "                \n",
    "                for chunk_idx, future in enumerate(future_results):\n",
    "                    chunk_new_cells, chunk_dead_indices = future.result()\n",
    "                    new_cells.extend(chunk_new_cells)\n",
    "                    dead_indices.extend([idx + offset for idx in chunk_dead_indices])\n",
    "                    offset += len(cell_chunks[chunk_idx])\n",
    "                \n",
    "                # Update cell list\n",
    "                cells = [cell for idx, cell in enumerate(cells) \n",
    "                        if idx not in dead_indices and cell.is_alive]\n",
    "                cells.extend(new_cells)\n",
    "    \n",
    "    return S_list, cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time and dimensions\n",
    "side_len = 750 #microns\n",
    "box_height = 300 #microns\n",
    "cell_size = 5 #microns\n",
    "cell_to_diff_ratio = 10\n",
    "density = 10 #mm^-2\n",
    "\n",
    "dt_diff = 1 #s\n",
    "dt_cell = 0.1 #hour\n",
    "dt_cell_to_diff_ratio = 360\n",
    "total_time = 10 #hours\n",
    "\n",
    "nsteps = int(t_final/dt_cell)\n",
    "time = np.arange(nsteps)/dt_diff + dt_diff\n",
    "\n",
    "D = 20 #um^2/s\n",
    "DS = D/np.square(cell_size*cell_to_diff_ratio) #cell_side^2/s\n",
    "#print(DS)\n",
    "\n",
    "nx,ny = int(side_len/(cell_size,cell_to_diff_ratio))\n",
    "S1 = np.zeros((nx, ny, nz))\n",
    "S2 = np.zeros((nx, ny, nz))\n",
    "D1, D2 = DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/cosmo_claude_220125_'\n",
    "\n",
    "n_strains = 2\n",
    "n_nutrients = 2\n",
    "\n",
    "#The dependencies of strain the strains on each nutrient. Within each strain and nutrient, COLUMN 1 is UPTAKE, \n",
    "#COLUMN 2 is RELEASE. 1 means they do that function, 0 means they do not\n",
    "dependencies = np.zeros((n_strains,n_nutrients,2))\n",
    "\n",
    "\n",
    "#This initialization is for classic CoSMO type crossfeeding.\n",
    "dependencies[0,0,0] = 1 #strain 1, uptake nutrient 1\n",
    "dependencies[0,1,1] = 1 #strain 1, release nutrient 2\n",
    "\n",
    "dependencies[1,1,0] = 1 #strain 2, uptake nutrient 2\n",
    "dependencies[1,0,1] = 1 #strain 2, release nutrient 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutrient initialization\n",
    "#Lys\n",
    "alphaL = 5.4 #nutrient required for reproduction (fmole)\n",
    "rL = 0.51 #Maximum growth rate (hr^-1)\n",
    "vmL = alphaL*rL #maximum uptake rate (fmole/hr)\n",
    "KL = 2.1e6 #Monod constant (fmole/ml)\n",
    "gammaL = 0.4 #release rate (fmole/(cell*hr))\n",
    "gammaL_s = gammaL/(60^2) #release rate (fmole/(cell*s))\n",
    "dL = 0.021 #death rate (hr^-1)\n",
    "\n",
    "#Ade\n",
    "alphaA = 3.1\n",
    "rA = 0.44\n",
    "vmA = alphaA*rA\n",
    "vmA_s = vmA/(60^2)\n",
    "KA = 1.3e6\n",
    "gammaA = 0.26\n",
    "dA = 0.015 #death rate (hr^-1). Should this be an order of magnitude higher?\n",
    "\n",
    "\n",
    "alpha_list = [alphaL,alphaA]\n",
    "vm_list = [vmL,vmA]\n",
    "gamma_list = [gammaL,gammaA]\n",
    "km_list = [KL,KA]\n",
    "d_list = [dL,dA]\n",
    "r_list = [rL,rA]\n",
    "\n",
    "\n",
    "uptake_rates = np.array([0.1, 0.2])\n",
    "release_rates = np.array([0.05, 0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run parallel simulation\n",
    "S_list_final, final_cells = parallel_simulate_system(\n",
    "    [S1, S2], [D1, D2], initial_cells, diff,\n",
    "    dt_diff, dt_cell, uptake_rates, release_rates,\n",
    "    total_time\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
