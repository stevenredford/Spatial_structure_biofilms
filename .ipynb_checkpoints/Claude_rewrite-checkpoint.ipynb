{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import numpy.typing as npt\n",
    "from typing import List, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GridChunk:\n",
    "    \"\"\"Data class for holding chunk information for parallel processing\"\"\"\n",
    "    start_idx: Tuple[int, int, int]\n",
    "    end_idx: Tuple[int, int, int]\n",
    "    S_chunk: List[npt.NDArray]\n",
    "    cells_in_chunk: List[Any]\n",
    "\n",
    "def split_grid_into_chunks(S_list: List[npt.NDArray], cells: List[Any], \n",
    "                          n_chunks: int) -> List[GridChunk]:\n",
    "    \"\"\"\n",
    "    Split the 3D grid and cells into chunks for parallel processing\n",
    "    \"\"\"\n",
    "    shape_S = S_list[0].shape\n",
    "    chunks_per_dim = int(np.cbrt(n_chunks))  # Cubic root for 3D splitting\n",
    "    \n",
    "    chunk_size = [s // chunks_per_dim for s in shape_S]\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(chunks_per_dim):\n",
    "        for j in range(chunks_per_dim):\n",
    "            for k in range(chunks_per_dim):\n",
    "                start_idx = (i * chunk_size[0], j * chunk_size[1], k * chunk_size[2])\n",
    "                end_idx = ((i + 1) * chunk_size[0], (j + 1) * chunk_size[1], \n",
    "                          (k + 1) * chunk_size[2])\n",
    "                \n",
    "                # Get cells in this chunk\n",
    "                cells_in_chunk = [\n",
    "                    cell for cell in cells if cell.is_alive and\n",
    "                    start_idx[0] <= cell.x < end_idx[0] and\n",
    "                    start_idx[1] <= cell.y < end_idx[1] and\n",
    "                    start_idx[2] <= cell.z < end_idx[2]\n",
    "                ]\n",
    "                \n",
    "                # Get nutrient chunks\n",
    "                S_chunk = [\n",
    "                    S[start_idx[0]:end_idx[0],\n",
    "                      start_idx[1]:end_idx[1],\n",
    "                      start_idx[2]:end_idx[2]].copy()\n",
    "                    for S in S_list\n",
    "                ]\n",
    "                \n",
    "                chunks.append(GridChunk(start_idx, end_idx, S_chunk, cells_in_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def process_chunk(chunk: GridChunk, D_list: List[float], diff: int, dt: float,\n",
    "                 uptake_rates: npt.NDArray, release_rates: npt.NDArray) -> Tuple[List[npt.NDArray], List[Any]]:\n",
    "    \"\"\"\n",
    "    Process a single chunk of the grid\n",
    "    \"\"\"\n",
    "    # Update nutrients in chunk\n",
    "    S_new_chunk = update_nutrient_fields(\n",
    "        chunk.S_chunk, D_list, chunk.cells_in_chunk, diff, dt,\n",
    "        uptake_rates, release_rates\n",
    "    )\n",
    "    \n",
    "    return S_new_chunk, chunk.cells_in_chunk\n",
    "\n",
    "def parallel_simulate_system(S_list: List[npt.NDArray], D_list: List[float], \n",
    "                           cells: List[Any], diff: int, dt_diff: float, \n",
    "                           dt_cell: float, uptake_rates: npt.NDArray, \n",
    "                           release_rates: npt.NDArray, total_time: float):\n",
    "    \"\"\"\n",
    "    Parallel implementation of system simulation\n",
    "    \"\"\"\n",
    "    steps_per_cell_update = int(dt_cell / dt_diff)\n",
    "    n_cell_updates = int(total_time / dt_cell)\n",
    "    \n",
    "    # Determine number of chunks based on CPU cores\n",
    "    n_cores = mp.cpu_count()\n",
    "    n_chunks = n_cores * 2  # Using 2 chunks per core for better load balancing\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_cores) as process_executor:\n",
    "        with ThreadPoolExecutor(max_workers=n_cores) as thread_executor:\n",
    "            \n",
    "            for cell_step in range(n_cell_updates):\n",
    "                # Parallel nutrient updates\n",
    "                for _ in range(steps_per_cell_update):\n",
    "                    # Split grid into chunks\n",
    "                    chunks = split_grid_into_chunks(S_list, cells, n_chunks)\n",
    "                    \n",
    "                    # Process chunks in parallel\n",
    "                    future_results = [\n",
    "                        process_executor.submit(\n",
    "                            process_chunk, chunk, D_list, diff, dt_diff,\n",
    "                            uptake_rates, release_rates\n",
    "                        )\n",
    "                        for chunk in chunks\n",
    "                    ]\n",
    "                    \n",
    "                    # Collect results\n",
    "                    chunk_results = [future.result() for future in future_results]\n",
    "                    \n",
    "                    # Merge chunk results back into main grid\n",
    "                    for chunk, (S_new_chunk, updated_cells) in zip(chunks, chunk_results):\n",
    "                        for i, S in enumerate(S_list):\n",
    "                            S[chunk.start_idx[0]:chunk.end_idx[0],\n",
    "                              chunk.start_idx[1]:chunk.end_idx[1],\n",
    "                              chunk.start_idx[2]:chunk.end_idx[2]] = S_new_chunk[i]\n",
    "                        \n",
    "                        # Update cell states\n",
    "                        for updated_cell in updated_cells:\n",
    "                            for cell in cells:\n",
    "                                if (cell.x == updated_cell.x and \n",
    "                                    cell.y == updated_cell.y and \n",
    "                                    cell.z == updated_cell.z):\n",
    "                                    cell.internal_nutrients = updated_cell.internal_nutrients\n",
    "                \n",
    "                # Parallel cell population updates\n",
    "                cell_chunks = np.array_split(cells, n_cores)\n",
    "                future_results = [\n",
    "                    thread_executor.submit(update_cell_population, chunk, dt_cell)\n",
    "                    for chunk in cell_chunks\n",
    "                ]\n",
    "                \n",
    "                # Collect and process cell updates\n",
    "                new_cells = []\n",
    "                dead_indices = []\n",
    "                offset = 0\n",
    "                \n",
    "                for chunk_idx, future in enumerate(future_results):\n",
    "                    chunk_new_cells, chunk_dead_indices = future.result()\n",
    "                    new_cells.extend(chunk_new_cells)\n",
    "                    dead_indices.extend([idx + offset for idx in chunk_dead_indices])\n",
    "                    offset += len(cell_chunks[chunk_idx])\n",
    "                \n",
    "                # Update cell list\n",
    "                cells = [cell for idx, cell in enumerate(cells) \n",
    "                        if idx not in dead_indices and cell.is_alive]\n",
    "                cells.extend(new_cells)\n",
    "    \n",
    "    return S_list, cells\n",
    "\n",
    "def compute_laplacian_3d(S):\n",
    "    \"\"\"Compute the 3D Laplacian of matrix S using convolution\"\"\"\n",
    "    kernel = np.array([\n",
    "        [[0, 0, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 0, 0]],\n",
    "        [[0, 1, 0],\n",
    "         [1, -6, 1],\n",
    "         [0, 1, 0]],\n",
    "        [[0, 0, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 0, 0]]\n",
    "    ])\n",
    "    return ndimage.convolve(S, kernel)\n",
    "\n",
    "# Previous functions remain the same\n",
    "def process_cell_nutrient_interactions(cells, S_list, shape_S, diff, dt, uptake_rates, release_rates):\n",
    "    \"\"\"Process nutrient uptake/release for all cells and update their states\"\"\"\n",
    "    # Implementation remains the same\n",
    "    pass\n",
    "\n",
    "def update_cell_population(cells, dt_cell):\n",
    "    \"\"\"Update cell population through death and reproduction\"\"\"\n",
    "    # Implementation remains the same\n",
    "    pass\n",
    "\n",
    "def update_nutrient_fields(S_list, D_list, cells, diff, dt, uptake_rates, release_rates):\n",
    "    \"\"\"Update nutrient concentration fields for one diffusion timestep\"\"\"\n",
    "    # Implementation remains the same\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "dt_diff = 0.1\n",
    "dt_cell = 36.0\n",
    "total_time = 1000.0\n",
    "\n",
    "# Initial conditions\n",
    "S1 = np.zeros((nx, ny, nz))\n",
    "S2 = np.zeros((nx, ny, nz))\n",
    "D1, D2 = 1.0, 0.5\n",
    "uptake_rates = np.array([0.1, 0.2])\n",
    "release_rates = np.array([0.05, 0.1])\n",
    "\n",
    "# Run parallel simulation\n",
    "S_list_final, final_cells = parallel_simulate_system(\n",
    "    [S1, S2], [D1, D2], initial_cells, diff,\n",
    "    dt_diff, dt_cell, uptake_rates, release_rates,\n",
    "    total_time\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
